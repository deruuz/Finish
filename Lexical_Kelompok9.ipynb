{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "ZzIeXCGEQnwn"
      },
      "outputs": [],
      "source": [
        "import string"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "alphabet_list = list(string.ascii_lowercase) #mengubah semua huruf ke lowercase\n",
        "state_list = ['q0', 'q1', 'q2', 'q3', 'q4', 'q5', 'q6', 'q7', 'q8', 'q9', 'q10',\n",
        "              'q11','q12', 'q13', 'q14', 'q15', 'q16', 'q17', 'q18',\n",
        "              'q19', 'q20', 'q21', 'q22','q23','q24']\n",
        "\n",
        "transition_table = {}\n",
        "\n",
        "for state in state_list:\n",
        "    for alphabet in alphabet_list:\n",
        "        transition_table[(state, alphabet)] = \"error\"\n",
        "        transition_table[(state, \"#\")]      = \"error\"\n",
        "        transition_table[(state, \" \")]      = \"error\"\n",
        "\n",
        "#Initial State (start)\n",
        "transition_table[\"q0\", \" \"] = \"q0\"\n",
        "\n",
        "#Finish State (FS)\n",
        "transition_table[(\"q26\", \"S\")] = \"accept\"\n",
        "\n",
        "#Subject\n",
        "#String \"for\"\n",
        "transition_table[(\"q0\", \"f\")]  = \"q1\"\n",
        "transition_table[(\"q1\", \"o\")]  = \"q2\"\n",
        "transition_table[(\"q2\", \"r\")]  = \"q3\"\n",
        "\n",
        "transition_table[(\"q3\", 'i')] = \"q4\"\n",
        "transition_table[(\"q4\", \">\")]  = \"q5\"\n",
        "transition_table[(\"q4\", \"<\")]  = \"q5\"\n",
        "\n",
        "transition_table[(\"q5\", 'a')] = \"q6\"\n",
        "transition_table[(\"q6\", \"{\")]  = \"q7\"\n",
        "transition_table[(\"q7\", \"f\")]  = \"q8\"\n",
        "transition_table[(\"q8\", \"m\")]  = \"q9\"\n",
        "transition_table[(\"q9\", \"t\")]  = \"q10\"\n",
        "transition_table[(\"q10\", \".\")]  = \"q11\"\n",
        "transition_table[(\"q11\", \"P\")]  = \"q12\"\n",
        "transition_table[(\"q12\", \"r\")]  = \"q13\"\n",
        "transition_table[(\"q13\", \"i\")]  = \"q14\"\n",
        "transition_table[(\"q14\", \"n\")]  = \"q15\"\n",
        "transition_table[(\"q15\", \"t\")]  = \"q16\"\n",
        "transition_table[(\"q16\", \"(\")]  = \"q17\"\n",
        "transition_table[(\"q17\", 'i')] = \"q18\"\n",
        "transition_table[(\"q18\", \")\")]  = \"q19\"\n",
        "transition_table[(\"q19\", \";\")]  = \"q20\"\n",
        "transition_table[(\"q20\", 'i')]  = \"q21\"\n",
        "transition_table[(\"q21\", \"+\")]  = \"q22\"\n",
        "transition_table[(\"q22\", \"+\")]  = \"q23\"\n",
        "transition_table[(\"q23\", \"}\")]  = \"q24\"\n"
      ],
      "metadata": {
        "id": "-Dx_XT2LQuNh"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_transition_table(transition_table):\n",
        "    print(\"Transition Table:\")\n",
        "    print(\"State\\tSymbol\\tNext State\")\n",
        "    print(\"------------------------\")\n",
        "    for key, value in transition_table.items():\n",
        "        state, symbol = key\n",
        "        next_state = value\n",
        "        if next_state != \"error\":\n",
        "            print(f\"{state}\\t{symbol}\\t{next_state}\")\n"
      ],
      "metadata": {
        "id": "ec5Y1_dDQxqV"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_transition_table(transition_table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcl5WaLFQ4M7",
        "outputId": "9e6ef4ad-bdcb-43af-c2ca-185b69e7ef81"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Transition Table:\n",
            "State\tSymbol\tNext State\n",
            "------------------------\n",
            "q0\t \tq0\n",
            "q0\tf\tq1\n",
            "q1\to\tq2\n",
            "q2\tr\tq3\n",
            "q3\ti\tq4\n",
            "q5\ta\tq6\n",
            "q7\tf\tq8\n",
            "q8\tm\tq9\n",
            "q9\tt\tq10\n",
            "q12\tr\tq13\n",
            "q13\ti\tq14\n",
            "q14\tn\tq15\n",
            "q15\tt\tq16\n",
            "q17\ti\tq18\n",
            "q20\ti\tq21\n",
            "q26\tS\taccept\n",
            "q4\t>\tq5\n",
            "q4\t<\tq5\n",
            "q6\t{\tq7\n",
            "q10\t.\tq11\n",
            "q11\tP\tq12\n",
            "q16\t(\tq17\n",
            "q18\t)\tq19\n",
            "q19\t;\tq20\n",
            "q21\t+\tq22\n",
            "q22\t+\tq23\n",
            "q23\t}\tq24\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def lexical(sentence):\n",
        "\n",
        "    #Initialization || menginialisasi semua state\n",
        "    alphabet_list = list(string.ascii_lowercase) #mengubah semua huruf ke lowercase\n",
        "    state_list = ['q0', 'q1', 'q2', 'q3', 'q4', 'q5', 'q6', 'q7', 'q8', 'q9',\n",
        "                  'q10','q11','q12', 'q13', 'q14', 'q15', 'q16', 'q17', 'q18',\n",
        "                  'q19', 'q20', 'q21', 'q22','q23','q24']\n",
        "\n",
        "\n",
        "    transition_table = {}\n",
        "\n",
        "    for state in state_list:\n",
        "        for alphabet in alphabet_list:\n",
        "            transition_table[(state, alphabet)] = \"error\"\n",
        "            transition_table[(state, \"#\")]      = \"error\"\n",
        "            transition_table[(state, \" \")]      = \"error\"\n",
        "\n",
        "    #Initial State (start)\n",
        "    transition_table[\"q0\", \" \"]    = \"q0\"\n",
        "\n",
        "    #Finish State (FS)\n",
        "    transition_table[(\"q24\", \"S\")] = \"accept\"\n",
        "\n",
        "\n",
        "    #String \"for\"\n",
        "    transition_table[(\"q0\", \"f\")]  = \"q1\"\n",
        "    transition_table[(\"q1\", \"o\")]  = \"q2\"\n",
        "    transition_table[(\"q2\", \"r\")]  = \"q3\"\n",
        "    transition_table[(\"q3\", 'i')]  = \"q4\"\n",
        "    transition_table[(\"q4\", \">\")]  = \"q5\"\n",
        "    transition_table[(\"q4\", \"<\")]  = \"q5\"\n",
        "    transition_table[(\"q5\", 'a')]  = \"q6\"\n",
        "    transition_table[(\"q6\", \"{\")]  = \"q7\"\n",
        "    transition_table[(\"q7\", \"f\")]  = \"q8\"\n",
        "    transition_table[(\"q8\", \"m\")]  = \"q9\"\n",
        "    transition_table[(\"q9\", \"t\")]  = \"q10\"\n",
        "    transition_table[(\"q10\", \".\")]  = \"q11\"\n",
        "    transition_table[(\"q11\", \"P\")]  = \"q12\"\n",
        "    transition_table[(\"q12\", \"r\")]  = \"q13\"\n",
        "    transition_table[(\"q13\", \"i\")]  = \"q14\"\n",
        "    transition_table[(\"q14\", \"n\")]  = \"q15\"\n",
        "    transition_table[(\"q15\", \"t\")]  = \"q16\"\n",
        "    transition_table[(\"q16\", \"(\")]  = \"q17\"\n",
        "    transition_table[(\"q17\", 'i')] = \"q18\"\n",
        "    transition_table[(\"q18\", \")\")]  = \"q19\"\n",
        "    transition_table[(\"q19\", \";\")]  = \"q20\"\n",
        "    transition_table[(\"q20\", 'i')]  = \"q21\"\n",
        "    transition_table[(\"q21\", \"+\")]  = \"q22\"\n",
        "    transition_table[(\"q22\", \"+\")]  = \"q23\"\n",
        "    transition_table[(\"q23\", \"}\")]  = \"q24\"\n",
        "\n",
        "    #Lexical Analysis\n",
        "    idx_char = 0\n",
        "    state = 'q0'\n",
        "    current_token = ''\n",
        "    while state != 'accept':\n",
        "        current_char = input_string[idx_char]\n",
        "        current_token += current_char\n",
        "        state = transition_table[(state, current_char)]\n",
        "        #print(current_char)\n",
        "        if state=='q24':\n",
        "            print('CURRENT TOKEN  : ', current_token, ', valid')\n",
        "            current_token = ''\n",
        "        if state ==\"error\":\n",
        "            print('ERROR')\n",
        "            break\n",
        "        idx_char = idx_char + 1\n",
        "\n",
        "\n",
        "    #Conclusion || state yang di accept\n",
        "    if state == \"accept\":\n",
        "        print('SEMUA TOKEN YANG DIINPUT : ', sentence, ', valid')\n",
        "    else:\n",
        "      print('')\n",
        "    return lexical"
      ],
      "metadata": {
        "id": "VgmFcTU1RLfI"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"======== TERMINAL ========\")\n",
        "print(\"for i<a{fmt.Print(i);i++}\")\n",
        "print(\"========================== \\n \")\n",
        "\n",
        "sentence = \"for i<a{fmt.Print(i);i++}\"\n",
        "sentence = sentence.replace(\" \", \"\")\n",
        "input_string = sentence + 'S'\n",
        "lexical(input_string)\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "print(\"======== TERMINAL ========\")\n",
        "print(\"for i>a{fmt.Print(i);i-}\")\n",
        "print(\"========================== \\n \")\n",
        "sentence = \"for i<a{fmt.Prit(i);i++}\"\n",
        "sentence = sentence.replace(\" \", \"\")\n",
        "input_string = sentence +'S'\n",
        "lexical(input_string)\n",
        "print(\"\\n\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rmk1wglBSb8I",
        "outputId": "6793dd36-c8f5-49e1-aa98-f0fea51ae0ef"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======== TERMINAL ========\n",
            "for i<a{fmt.Print(i);i++}\n",
            "========================== \n",
            " \n",
            "CURRENT TOKEN  :  fori<a{fmt.Print(i);i++} , valid\n",
            "SEMUA TOKEN YANG DIINPUT :  fori<a{fmt.Print(i);i++}S , valid\n",
            "\n",
            "\n",
            "\n",
            "======== TERMINAL ========\n",
            "for i>a{fmt.Print(i);i-}\n",
            "========================== \n",
            " \n",
            "ERROR\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Token types\n",
        "TOKEN_FOR = 'FOR'\n",
        "TOKEN_IDENTIFIER = 'IDENTIFIER'\n",
        "TOKEN_LESS_THAN = 'LESS_THAN'\n",
        "TOKEN_MORE_THAN = 'MORE_THAN'\n",
        "TOKEN_OPEN_BRACE = 'OPEN_BRACE'\n",
        "TOKEN_CLOSE_BRACE = 'CLOSE_BRACE'\n",
        "TOKEN_SEMICOLON = 'SEMICOLON'\n",
        "TOKEN_DOT = 'DOT'\n",
        "TOKEN_INCREMENT = 'INCREMENT'\n",
        "TOKEN_LPAREN = 'LPAREN'\n",
        "TOKEN_RPAREN = 'RPAREN'\n",
        "\n",
        "# Lexical rules\n",
        "LEXICAL_RULES = [\n",
        "    (TOKEN_FOR, 'for'),\n",
        "    (TOKEN_LESS_THAN, '<'),\n",
        "    (TOKEN_MORE_THAN, '>'),\n",
        "    (TOKEN_OPEN_BRACE, '{'),\n",
        "    (TOKEN_CLOSE_BRACE, '}'),\n",
        "    (TOKEN_SEMICOLON, ';'),\n",
        "    (TOKEN_DOT, '.'),\n",
        "    (TOKEN_INCREMENT, '+'),\n",
        "    (TOKEN_DECREMENT, '-'),\n",
        "    (TOKEN_LPAREN, '('),\n",
        "    (TOKEN_RPAREN, ')')\n",
        "]\n",
        "\n",
        "def tokenize(code):\n",
        "    tokens = []\n",
        "    position = 0\n",
        "    code_len = len(code)\n",
        "\n",
        "    while position < code_len:\n",
        "        if code[position].isspace():\n",
        "            position += 1\n",
        "        elif code[position:position+3] == 'for':\n",
        "            tokens.append((TOKEN_FOR, 'for'))\n",
        "            position += 3\n",
        "        elif code[position] == '<':\n",
        "            tokens.append((TOKEN_LESS_THAN, '<'))\n",
        "            position += 1\n",
        "        elif code[position] == '>':\n",
        "            tokens.append((TOKEN_MORE_THAN, '>'))\n",
        "            position += 1\n",
        "        elif code[position] == '{':\n",
        "            tokens.append((TOKEN_OPEN_BRACE, '{'))\n",
        "            position += 1\n",
        "        elif code[position] == '(':\n",
        "            tokens.append((TOKEN_LPAREN, '('))\n",
        "            position += 1\n",
        "        elif code[position] == ')':\n",
        "            tokens.append((TOKEN_RPAREN, ')'))\n",
        "            position += 1\n",
        "        elif code[position] == '}':\n",
        "            tokens.append((TOKEN_CLOSE_BRACE, '}'))\n",
        "            position += 1\n",
        "        elif code[position] == ';':\n",
        "            tokens.append((TOKEN_SEMICOLON, ';'))\n",
        "            position += 1\n",
        "        elif code[position] == '.':\n",
        "            tokens.append((TOKEN_DOT, '.'))\n",
        "            position += 1\n",
        "        elif code[position] == '+':\n",
        "            tokens.append((TOKEN_INCREMENT, '+'))\n",
        "            position += 1\n",
        "        elif code[position] == '-':\n",
        "            tokens.append((TOKEN_DECREMENT, '-'))\n",
        "            position += 1\n",
        "        elif code[position].isalpha() or code[position] == '_':\n",
        "            identifier = code[position]\n",
        "            position += 1\n",
        "            while position < code_len and (code[position].isalnum() or code[position] == '_'):\n",
        "                identifier += code[position]\n",
        "                position += 1\n",
        "            tokens.append((TOKEN_IDENTIFIER, identifier))\n",
        "        else:\n",
        "            position += 1\n",
        "\n",
        "    return tokens\n",
        "\n",
        "# Test the lexer\n",
        "#syntak valid : for i<a{fmt.Print(i);i++}\n",
        "code = 'for i<a{fmt.Print(i);i++}'\n",
        "tokens = tokenize(code)\n",
        "\n",
        "for token_type, value in tokens:\n",
        "    print(f\"Token type: {token_type}\\tValue: {value}\")\n"
      ],
      "metadata": {
        "id": "MtGVzKv1XDOp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afea8141-0bc6-4f2a-f034-48980cc9a634"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token type: FOR\tValue: for\n",
            "Token type: IDENTIFIER\tValue: i\n",
            "Token type: LESS_THAN\tValue: <\n",
            "Token type: IDENTIFIER\tValue: a\n",
            "Token type: OPEN_BRACE\tValue: {\n",
            "Token type: IDENTIFIER\tValue: fmt\n",
            "Token type: DOT\tValue: .\n",
            "Token type: IDENTIFIER\tValue: Print\n",
            "Token type: LPAREN\tValue: (\n",
            "Token type: IDENTIFIER\tValue: i\n",
            "Token type: RPAREN\tValue: )\n",
            "Token type: SEMICOLON\tValue: ;\n",
            "Token type: IDENTIFIER\tValue: i\n",
            "Token type: INCREMENT\tValue: +\n",
            "Token type: INCREMENT\tValue: +\n",
            "Token type: CLOSE_BRACE\tValue: }\n"
          ]
        }
      ]
    }
  ]
}